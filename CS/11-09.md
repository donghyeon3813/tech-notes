1. IPC가 무엇이고, 어떤 종류가 있는지 설명해 주세요.
 - IPC란 프로세스간의 통신을 하기위한 방법을 뜻하며, 공유메모리(뮤텍스, 세마포어), 파일, 소켓, 명명 파이프, 메시지 큐가 있습니다.
2. Shared Memory가 무엇이며, 사용할 때 유의해야 할 점에 대해 설명해 주세요.
 - Shared Memory란 여러 프로세스에서 동일한 메모리 블록에 대한 접근 권한이 부여되어 프로세스가 서로 통신할 수 있도록 공유버퍼를 생성하는 것을 말합니다. 동시에 여러 프로세스가 같은 메모리 블록에 접근하게 된다면 동기화 문제가 발생할 수 있기때문에 이를 컨트롤할 수 있는 세마포어나 뮤텍스와 기법이 필요할 수 있습니다.
3. 메시지 큐는 단방향이라고 할 수 있나요?
 - 메시지 큐는 기본적으로 단방향이지만, 송신용 큐와 수신용 큐를 각각 만들어 프로세스 간에 양방향 통신 구조를 구현할 수 있습니다.

4. Thread Safe 하다는 것은 어떤 의미인가요?
- Thread Safe란 여러 스레드가 동시에 같은 객체나 자원에 접근해도 잘못된 결과가 발생하지 않는 상태를 말합니다.
예를 들어 단순한 count++ 연산은 여러 스레드가 동시에 접근하면 값이 꼬일 수 있지만, AtomicInteger.incrementAndGet()을 사용하면 원자적으로 동작해 Thread Safe하게 동작합니다. 즉, 동시성 환경에서도 일관성과 무결성을 보장하는 걸 의미합니다.
5. Thread Safe 를 보장하기 위해 어떤 방법을 사용할 수 있나요?
- Thread Safe를 보장하기 위해 가장 기본적으로는 synchronized 같은 락을 사용합니다.
하지만 락은 성능 오버헤드가 크기 때문에 상황에 따라 AtomicInteger처럼 CAS 기반의 원자 연산이나, 불변 객체 설계, ThreadLocal, ConcurrentHashMap 같은 자료구조를 활용할 수도 있습니다.
6. Peterson's Algorithm 이 무엇이며, 한계점에 대해 설명해 주세요.
- Peterson’s Algorithm은 두 스레드 간의 상호 배제를 보장하기 위한 소프트웨어 알고리즘입니다.
flag와 turn 변수를 이용해서 서로 임계 구역에 진입하지 않도록 양보하는 구조입니다.
다만 이 방법은 두 스레드만 적용 가능하고, Busy Waiting으로 CPU를 낭비하며, 현대 멀티코어 CPU에서는 캐시 일관성 문제로 제대로 동작하지 않을 수 있습니다.
그래서 실제 시스템에서는 하드웨어 수준의 Test-and-Set이나 Compare-And-Swap 같은 명령어로 락을 구현합니다.
7. Race Condition 이 무엇인가요?
- Race Condition은 여러 스레드가 동시에 같은 자원을 수정하거나 읽는 과정에서 실행 순서에 따라 결과가 달라지는 상황입니다.
예를 들어 count++ 연산이 세 단계(읽기 → 증가 → 쓰기)로 분리되어 있어서, 두 스레드가 동시에 실행하면 최종 결과가 2가 아니라 1이 될 수 있습니다.
이를 방지하기 위해 락이나 원자적 연산을 사용해서 동시 접근을 제어해야 합니다.
8. Thread Safe를 구현하기 위해 반드시 락을 사용해야 할까요? 그렇지 않다면, 어떤 다른 방법이 있을까요?
- 반드시 락을 써야 하는 건 아닙니다.
예를 들어 AtomicInteger나 AtomicReference는 내부적으로 Compare-And-Swap(CAS)을 사용해서 락 없이도 Thread Safe하게 동작합니다.
또, 불변 객체를 사용하면 상태 변경이 없으므로 Race Condition 자체가 발생하지 않습니다.
실무에서는 락 기반보다 이런 비차단(lock-free) 접근 방식을 선호하는 경우도 많습니다

9. Thread Pool, Monitor, Fork-Join에 대해 설명해 주세요.
- Thread Pool은 미리 생성된 스레드 집합을 재사용해, 스레드 생성·소멸 비용을 줄이는 구조입니다.
Monitor는 한 객체의 임계영역을 보호하기 위한 동기화 매커니즘으로, 한 번에 한 스레드만 접근하게 합니다. Java에선 synchronized 블록이 모니터를 기반으로 동작하죠.
Fork-Join은 큰 작업을 여러 작은 작업으로 나누어 병렬 실행 후 결과를 합치는 패턴으로, CPU 코어를 최대한 활용할 수 있습니다.

10. Thread Pool을 사용한다고 가정하면, 어떤 기준으로 스레드의 수를 결정할 것인가요?
- 스레드 풀 크기는 작업의 성격에 따라 다르게 설정해야 합니다.
CPU 연산 위주라면 코어 수와 동일하거나 +1 정도로 맞추는 게 효율적이고,
네트워크나 파일 I/O처럼 대기 시간이 긴 작업이라면 코어 수의 2~3배 이상으로 늘려 병렬성을 높이는 것이 좋습니다.
실제로는 프로파일링을 통해 작업의 대기/연산 비율을 측정한 뒤 적정 스레드 수를 조정하는 방식이 가장 안정적입니다.

11. 어떤 데이터를 정렬 하려고 합니다. 어떤 방식의 전략을 사용하는 것이 가장 안전하면서도 좋은 성능을 낼 수 있을까요?
- “데이터의 크기, 안정성(Stable Sort 필요 여부), 메모리 제약, 그리고 병렬성 여부에 따라 다릅니다.
일반적으로는 평균 O(n log n)의 Quick Sort가 빠르지만, 안정성이 필요한 경우 Merge Sort가 더 안전합니다.
대용량 데이터나 다중 코어 환경이라면 Merge Sort 기반의 병렬 정렬 전략이 가장 효율적입니다.

12. 캐시 메모리 및 메모리 계층성에 대해 설명해 주세요.
- 메모리 계층 구조는 CPU에서 멀어질수록 느리고 용량이 큰 구조로 되어 있습니다.
캐시 메모리는 CPU와 메인 메모리 사이에 위치해, 자주 사용하는 데이터를 임시로 저장함으로써 메모리 접근 속도를 개선합니다.
이를 통해 CPU가 메모리 병목 없이 연산을 지속할 수 있게 돕습니다.
13. 캐시 메모리는 어디에 위치해 있나요?
- 캐시 메모리는 CPU와 메인 메모리 사이에 위치하며, 실제로는 CPU 칩 내부에 있습니다.
L1, L2 캐시는 각 코어마다 따로 존재하고, L3 캐시는 여러 코어가 공유하는 형태로 구성되어 있습니다.
14. L1, L2 캐시에 대해 설명해 주세요.
- L1 캐시는 CPU 코어에 가장 가까운 캐시로, 명령어용과 데이터용으로 나뉘어 있습니다.
속도는 가장 빠르지만 용량이 작고, L1에 없는 데이터는 L2 캐시에서 찾게 됩니다.
L2는 L1보다 느리지만 용량이 크며, L1을 보조하는 역할을 합니다.
15. 캐시에 올라오는 데이터는 어떻게 관리되나요?
- 캐시의 데이터는 지역성 원리에 따라 관리되며, 공간이 가득 차면 교체 정책에 따라 오래 사용되지 않은 데이터를 제거합니다.
대표적인 방식으로는 LRU(가장 오랫동안 사용되지 않은 데이터 제거)가 있습니다.
16. 캐시간의 동기화는 어떻게 이루어지나요?
- 멀티코어 환경에서는 동일한 데이터를 여러 캐시에 복사해둘 수 있기 때문에,
한 코어가 데이터를 변경하면 다른 캐시에서도 이를 인식해야 합니다.
이를 캐시 일관성 문제라고 하며, MESI 같은 프로토콜을 통해 각 캐시 라인의 상태를 관리하고 동기화를 보장합니다.
17. 캐시 메모리의 Mapping 방식에 대해 설명해 주세요.
- 캐시 매핑은 메모리 블록을 캐시에 배치하는 방법을 의미합니다.
직접 매핑은 단일 위치에만 저장되어 빠르지만 충돌이 많고,
완전 연관 매핑은 어디든 저장 가능하지만 탐색이 느립니다.
현재 CPU는 이 둘을 절충한 집합 연관 매핑을 사용합니다.”
18. 캐시의 지역성에 대해 설명해 주세요.
- 지역성은 프로그램이 메모리를 접근할 때 일정한 패턴을 보이는 특성입니다.
시간적 지역성은 최근에 접근한 데이터를 다시 사용할 가능성이 높다는 의미이고,
공간적 지역성은 접근한 데이터의 근처 데이터가 다음에 접근될 확률이 높다는 의미입니다.
캐시는 이 두 가지 지역성을 활용해 성능을 높입니다
19. 캐시의 지역성을 기반으로, 이차원 배열을 가로/세로로 탐색했을 때의 성능 차이에 대해 설명해 주세요.
- 이차원 배열은 메모리에 행 단위(Row-major)로 연속 저장됩니다.
따라서 가로 방향으로 순차 접근하면 공간 지역성이 높아 캐시 효율이 좋지만,
세로 방향으로 접근하면 각 접근이 서로 다른 메모리 블록에 위치하게 되어 캐시 미스가 많이 발생합니다.
20. 캐시의 공간 지역성은 어떻게 구현될 수 있을까요? (힌트: 캐시는 어떤 단위로 저장되고 관리될까요?)
- 시는 개별 변수가 아니라 캐시 라인이라는 일정 크기의 블록 단위로 데이터를 저장합니다.
한 번 데이터를 가져올 때 인접한 데이터까지 미리 가져오기 때문에,
이후 근처 데이터를 접근할 때 캐시 히트가 발생하게 되어 공간 지역성을 활용할 수 있습니다.
21. 메모리의 연속할당 방식 세 가지를 설명해주세요. (first-fit, best-fit, worst-fit)
- 연속할당 방식은 프로세스 크기에 맞게 메모리의 빈 영역 중 어느 곳에 배치할지를 결정하는 방법입니다.
First-fit은 앞에서부터 탐색해 처음 맞는 곳에 배치하는 방식이고,
Best-fit은 가장 크기가 근접한 공간을 찾아 낭비를 줄이려 합니다.
Worst-fit은 가장 큰 공간에 배치하여 큰 여유 공간을 남겨두는 방식입니다.
22. worst-fit 은 언제 사용할 수 있을까요?
- Worst-fit은 가장 큰 공간에 프로세스를 배치해, 나머지 빈 공간들을 가능한 크게 유지하는 방식입니다.
실제로는 큰 공간이 금방 여러 조각으로 나뉘어 외부 단편화가 증가하기 때문에 잘 쓰이지 않습니다.
다만 프로세스의 크기 분포가 매우 다양하고, 큰 공간을 자주 재활용해야 하는 환경에서는 사용될 수 있습니다.
23. 성능이 가장 좋은 알고리즘은 무엇일까요?
- 일반적으로 First-fit이 탐색이 빠르고 전체 효율이 가장 좋다고 평가됩니다.
Best-fit은 이론적으로 메모리 낭비를 줄이지만 탐색 오버헤드가 커서 실제로는 비효율적입니다.
따라서 대부분의 시스템에서는 First-fit이 기본 정책으로 사용됩니다.
