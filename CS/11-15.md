1. Thrashing 이란 무엇인가요?
- Thrashing은 메모리가 부족해 프로세스들이 계속해서 페이지를 교체하느라 CPU보다 디스크 I/O에 더 많은 시간을 소모하는 현상입니다. 이로 인해 시스템 성능이 급격히 저하됩니다.
2. Thrashing 발생 시, 어떻게 완화할 수 있을까요?
- 메모리를 높이거나, HDD를 사용한다면 SSD로 변경하거나 또는 작업세트와 PFF가 있습니다.
  + 작업세트: 프로세스의 과거 사용 이력인 지역성을 통해 결정된 페이지 집합을 만들어서 미리 메모리에 로드하는 것
  + PFF: 페이지 폴트 빈도를 조절하는 방법으로 상한선과 하한선을 만드는 방법 상한선에 도달하면 프레임을 늘리고 하하선에 도달하면 프레임을 줄인다. 
3. 가상 메모리란 무엇인가요?
- 가상 메모리는 프로세스가 실제 물리 메모리보다 더 큰 메모리를 사용하는 것처럼 보이게 하는 추상화 기술입니다.
운영체제가 페이지 단위로 필요한 부분만 물리 메모리에 매핑하고, 나머지는 디스크의 스왑 영역에 저장하여 관리합니다
4. 가상 메모리가 가능한 이유가 무엇일까요?
- 가상 메모리는 하드웨어의 MMU가 가상 주소를 물리 주소로 변환해 주고, OS가 페이지 테이블을 관리하기 때문에 가능합니다.
이 덕분에 프로세스는 실제 물리 메모리보다 큰 공간을 독립적으로 사용할 수 있습니다
5. Page Fault가 발생했을 때, 어떻게 처리하는지 설명해 주세요.
- 페이지 폴트가 발생하면 OS가 디스크에서 해당 페이지를 읽어 물리 메모리에 적재하고, 페이지 테이블을 갱신한 뒤 명령을 재시도합니다.
만약 물리 메모리가 가득 차 있다면 교체 알고리즘으로 기존 페이지를 스왑 아웃합니다.
6. 페이지 크기에 대한 Trade-Off를 설명해 주세요.
- 페이지 크기는 내부 단편화와 관리 오버헤드 사이의 트레이드오프가 있습니다.
작은 페이지는 공간 낭비를 줄이지만 페이지 테이블이 커지고, 큰 페이지는 관리가 단순해지지만 내부 단편화가 커집니다.
7. 페이지 크기가 커지면, 페이지 폴트가 더 많이 발생한다고 할 수 있나요?
- 페이지 크기가 커지면 한 번에 더 많은 데이터를 읽기 때문에 페이지 폴트는 줄 수도 있습니다.
하지만 내부 단편화와 불필요한 적재로 메모리 효율은 나빠질 수 있습니다.
8. 세그멘테이션 방식을 사용하고 있다면, 가상 메모리를 사용할 수 없을까요?
- 세그멘테이션을 사용하더라도 가상 메모리를 사용할 수 있습니다.
현대 OS는 세그먼트 단위로 프로그램을 나누고, 각 세그먼트를 다시 페이지 단위로 관리하는 방식으로 두 기술을 혼합해 사용합니다.

9. 세그멘테이션과 페이징의 차이점은 무엇인가요?
- 페이징은 메모리를 고정 크기의 페이지 단위로 나누어 관리하는 방식이고,
세그멘테이션은 코드나 데이터 등 의미 단위로 가변 크기로 나누는 방식입니다.
페이징은 내부 단편화가, 세그멘테이션은 외부 단편화가 발생할 수 있습니다.
10. 페이지와 프레임의 차이에 대해 설명해 주세요.
- 페이지는 가상 메모리의 단위이고, 프레임은 물리 메모리의 단위입니다.
두 크기는 동일하며, 페이지는 실행 시 프레임에 매핑되어 실제 메모리에 적재됩니다.
11. 내부 단편화와, 외부 단편화에 대해 설명해 주세요.
- 내부 단편화는 고정 크기 블록 내부에서 낭비되는 공간이고,
외부 단편화는 가변 크기 블록 사이에 연속되지 않은 빈 공간이 흩어져 생기는 현상입니다.

12. 페이지에서 실제 주소를 어떻게 가져올 수 있는지 설명해 주세요.
- 가상 주소는 페이지 번호와 오프셋으로 구성됩니다.
MMU가 페이지 테이블을 참조해 페이지 번호에 대응하는 프레임 번호를 찾고,
그 프레임 번호와 오프셋을 결합해 물리 주소를 계산합니다.
이 과정은 하드웨어(TLB 포함)에서 자동으로 수행됩니다.
13. 어떤 주소공간이 있을 때, 이 공간이 수정 가능한지 확인할 수 있는 방법이 있나요?
- 페이지 테이블 엔트리에는 각 페이지의 접근 권한 비트가 포함되어 있습니다.
이 비트를 통해 읽기/쓰기/실행 여부를 제어하므로,
페이지 테이블을 확인하면 해당 주소 공간이 수정 가능한지 알 수 있습니다.
16. C/C++ 개발을 하게 되면 Segmentation Fault 라는 에러를 접할 수 있을텐데, 이 에러는 세그멘테이션/페이징과 어떤 관계가 있을까요?
- Segmentation Fault는 프로세스가 접근 권한이 없는 메모리 영역에 접근할 때 발생하는 예외입니다.
과거 세그멘테이션 구조에서는 세그먼트를 벗어나는 접근일 때 발생했고,
현대 OS에서는 페이징 기반 보호 비트 위반일 때 같은 에러가 발생합니다.

17. TLB는 무엇인가요?
- TLB는 가상 주소 → 물리 주소 변환 결과(PTE)를 저장해두는 하드웨어 캐시입니다.
TLB를 사용하면 페이지 테이블을 메모리에서 읽지 않아도 되어 주소 변환 시간이 크게 줄기 때문입니다.
TLB hit 시 변환이 CPU 내부에서 즉시 끝나며, RAM 접근이 필요 없어 매우 빠릅니다.

18. TLB를 쓰면 왜 빨라지나요?
- TLB는 이미 변환된 물리주소를 가지고 있기때문에 변환작업을 거치지 않아도 되서입니다.

19. MMU가 무엇인가요?
- MMU는 가상 주소를 물리 주소로 변환하고, 접근 권한을 검사하는 하드웨어 장치(CPU 내부)입니다.
내부에 TLB와 페이지 테이블 워커를 포함하여 CPU의 모든 메모리 접근을 관리합니다.

20. TLB와 MMU는 어디에 위치해 있나요?
- MMU는 CPU 내부에 위치합니다.
TLB는 MMU 내부에 포함된 고속 캐시입니다.
CPU → MMU → TLB 순으로 주소 변환이 진행됩니다.

21. 코어가 여러개라면, TLB는 어떻게 동기화 할 수 있을까요?
- 멀티코어에서는 각 코어가 독립적인 TLB를 가지고 있기 때문에, 페이지 테이블이 바뀌면 OS가 IPI를 보내서 각 코어의 해당 TLB 엔트리를 무효화하는 TLB Shootdown 방식으로 동기화를 합니다.
OS가 페이지 테이블을 변경하면, 각 코어에 IPI(Inter-Processor Interrupt) 를 보내
해당 가상 주소의 TLB 엔트리를 무효화(invalidate)하도록 지시합니다.
22. TLB 관점에서, Context Switching 발생 시 어떤 변화가 발생하는지 설명해 주세요.
- Context Switch가 발생하면 CPU는 다른 페이지 테이블을 사용하게 되므로 TLB 엔트리를 무효화해야 합니다.
ASID가 없는 구조는 TLB 전체를 flush하고, ASID가 있으면 ASID만 교체해 기존 TLB를 그대로 두고 구분할 수 있습니다.
23. 동기화를 구현하기 위한 하드웨어적인 해결 방법에 대해 설명해 주세요.
- 하드웨어는 세 가지로 동기화를 지원합니다.
첫째, CAS 같은 Atomic 연산,
둘째, Memory Barrier를 통한 명령 재배치 방지,
셋째, MESI 같은 캐시 일관성 프로토콜입니다.
이 세 가지가 멀티코어 환경에서 올바른 동기화를 보장합니다.
24. volatile 키워드는 어떤 의미가 있나요?
- volatile은 컴파일러에게 ‘이 변수는 예상치 못하게 바뀔 수 있으니 절대 캐싱하지 말고 매번 메모리에서 직접 읽어라’ 라고 지시하는 키워드입니다.
가시성은 보장하지만 원자성은 보장하지 않습니다.
25. 싱글코어가 아니라 멀티코어라면, 어떻게 동기화가 이뤄질까요?
- 멀티코어에서는 먼저 MESI 같은 캐시 일관성 프로토콜이 변수의 최신 값을 각 코어에 맞춰 주고,
그 위에서 CAS 같은 Atomic 연산과 Memory Barrier가 재배치 문제를 해결하며,
OS나 언어는 이 기반 위에서 락·스핀락 같은 동기화 프리미티브를 제공합니다.
