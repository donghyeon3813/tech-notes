1. Thrashing 이란 무엇인가요?
- Thrashing은 메모리가 부족해 프로세스들이 계속해서 페이지를 교체하느라 CPU보다 디스크 I/O에 더 많은 시간을 소모하는 현상입니다. 이로 인해 시스템 성능이 급격히 저하됩니다.
2. Thrashing 발생 시, 어떻게 완화할 수 있을까요?
- 메모리를 높이거나, HDD를 사용한다면 SSD로 변경하거나 또는 작업세트와 PFF가 있습니다.
  + 작업세트: 프로세스의 과거 사용 이력인 지역성을 통해 결정된 페이지 집합을 만들어서 미리 메모리에 로드하는 것
  + PFF: 페이지 폴트 빈도를 조절하는 방법으로 상한선과 하한선을 만드는 방법 상한선에 도달하면 프레임을 늘리고 하하선에 도달하면 프레임을 줄인다. 
3. 가상 메모리란 무엇인가요?
- 가상 메모리는 프로세스가 실제 물리 메모리보다 더 큰 메모리를 사용하는 것처럼 보이게 하는 추상화 기술입니다.
운영체제가 페이지 단위로 필요한 부분만 물리 메모리에 매핑하고, 나머지는 디스크의 스왑 영역에 저장하여 관리합니다
4. 가상 메모리가 가능한 이유가 무엇일까요?
- 가상 메모리는 하드웨어의 MMU가 가상 주소를 물리 주소로 변환해 주고, OS가 페이지 테이블을 관리하기 때문에 가능합니다.
이 덕분에 프로세스는 실제 물리 메모리보다 큰 공간을 독립적으로 사용할 수 있습니다
5. Page Fault가 발생했을 때, 어떻게 처리하는지 설명해 주세요.
- 페이지 폴트가 발생하면 OS가 디스크에서 해당 페이지를 읽어 물리 메모리에 적재하고, 페이지 테이블을 갱신한 뒤 명령을 재시도합니다.
만약 물리 메모리가 가득 차 있다면 교체 알고리즘으로 기존 페이지를 스왑 아웃합니다.
6. 페이지 크기에 대한 Trade-Off를 설명해 주세요.
- 페이지 크기는 내부 단편화와 관리 오버헤드 사이의 트레이드오프가 있습니다.
작은 페이지는 공간 낭비를 줄이지만 페이지 테이블이 커지고, 큰 페이지는 관리가 단순해지지만 내부 단편화가 커집니다.
7. 페이지 크기가 커지면, 페이지 폴트가 더 많이 발생한다고 할 수 있나요?
- 페이지 크기가 커지면 한 번에 더 많은 데이터를 읽기 때문에 페이지 폴트는 줄 수도 있습니다.
하지만 내부 단편화와 불필요한 적재로 메모리 효율은 나빠질 수 있습니다.
8. 세그멘테이션 방식을 사용하고 있다면, 가상 메모리를 사용할 수 없을까요?
- 세그멘테이션을 사용하더라도 가상 메모리를 사용할 수 있습니다.
현대 OS는 세그먼트 단위로 프로그램을 나누고, 각 세그먼트를 다시 페이지 단위로 관리하는 방식으로 두 기술을 혼합해 사용합니다.

9. 세그멘테이션과 페이징의 차이점은 무엇인가요?
- 페이징은 메모리를 고정 크기의 페이지 단위로 나누어 관리하는 방식이고,
세그멘테이션은 코드나 데이터 등 의미 단위로 가변 크기로 나누는 방식입니다.
페이징은 내부 단편화가, 세그멘테이션은 외부 단편화가 발생할 수 있습니다.
10. 페이지와 프레임의 차이에 대해 설명해 주세요.
- 페이지는 가상 메모리의 단위이고, 프레임은 물리 메모리의 단위입니다.
두 크기는 동일하며, 페이지는 실행 시 프레임에 매핑되어 실제 메모리에 적재됩니다.
11. 내부 단편화와, 외부 단편화에 대해 설명해 주세요.
- 내부 단편화는 고정 크기 블록 내부에서 낭비되는 공간이고,
외부 단편화는 가변 크기 블록 사이에 연속되지 않은 빈 공간이 흩어져 생기는 현상입니다.

12. 페이지에서 실제 주소를 어떻게 가져올 수 있는지 설명해 주세요.
- 가상 주소는 페이지 번호와 오프셋으로 구성됩니다.
MMU가 페이지 테이블을 참조해 페이지 번호에 대응하는 프레임 번호를 찾고,
그 프레임 번호와 오프셋을 결합해 물리 주소를 계산합니다.
이 과정은 하드웨어(TLB 포함)에서 자동으로 수행됩니다.
13. 어떤 주소공간이 있을 때, 이 공간이 수정 가능한지 확인할 수 있는 방법이 있나요?
- 페이지 테이블 엔트리에는 각 페이지의 접근 권한 비트가 포함되어 있습니다.
이 비트를 통해 읽기/쓰기/실행 여부를 제어하므로,
페이지 테이블을 확인하면 해당 주소 공간이 수정 가능한지 알 수 있습니다.
16. C/C++ 개발을 하게 되면 Segmentation Fault 라는 에러를 접할 수 있을텐데, 이 에러는 세그멘테이션/페이징과 어떤 관계가 있을까요?
- Segmentation Fault는 프로세스가 접근 권한이 없는 메모리 영역에 접근할 때 발생하는 예외입니다.
과거 세그멘테이션 구조에서는 세그먼트를 벗어나는 접근일 때 발생했고,
현대 OS에서는 페이징 기반 보호 비트 위반일 때 같은 에러가 발생합니다.

17. TLB는 무엇인가요?
- TLB는 가상 주소 → 물리 주소 변환 결과(PTE)를 저장해두는 하드웨어 캐시입니다.
TLB를 사용하면 페이지 테이블을 메모리에서 읽지 않아도 되어 주소 변환 시간이 크게 줄기 때문입니다.
TLB hit 시 변환이 CPU 내부에서 즉시 끝나며, RAM 접근이 필요 없어 매우 빠릅니다.

18. TLB를 쓰면 왜 빨라지나요?
- TLB는 이미 변환된 물리주소를 가지고 있기때문에 변환작업을 거치지 않아도 되서입니다.

19. MMU가 무엇인가요?
- MMU는 가상 주소를 물리 주소로 변환하고, 접근 권한을 검사하는 하드웨어 장치(CPU 내부)입니다.
내부에 TLB와 페이지 테이블 워커를 포함하여 CPU의 모든 메모리 접근을 관리합니다.

20. TLB와 MMU는 어디에 위치해 있나요?
- MMU는 CPU 내부에 위치합니다.
TLB는 MMU 내부에 포함된 고속 캐시입니다.
CPU → MMU → TLB 순으로 주소 변환이 진행됩니다.

21. 코어가 여러개라면, TLB는 어떻게 동기화 할 수 있을까요?
- 멀티코어에서는 각 코어가 독립적인 TLB를 가지고 있기 때문에, 페이지 테이블이 바뀌면 OS가 IPI를 보내서 각 코어의 해당 TLB 엔트리를 무효화하는 TLB Shootdown 방식으로 동기화를 합니다.
OS가 페이지 테이블을 변경하면, 각 코어에 IPI(Inter-Processor Interrupt) 를 보내
해당 가상 주소의 TLB 엔트리를 무효화(invalidate)하도록 지시합니다.
22. TLB 관점에서, Context Switching 발생 시 어떤 변화가 발생하는지 설명해 주세요.
- Context Switch가 발생하면 CPU는 다른 페이지 테이블을 사용하게 되므로 TLB 엔트리를 무효화해야 합니다.
ASID가 없는 구조는 TLB 전체를 flush하고, ASID가 있으면 ASID만 교체해 기존 TLB를 그대로 두고 구분할 수 있습니다.
23. 동기화를 구현하기 위한 하드웨어적인 해결 방법에 대해 설명해 주세요.
- 하드웨어는 세 가지로 동기화를 지원합니다.
첫째, CAS 같은 Atomic 연산,
둘째, Memory Barrier를 통한 명령 재배치 방지,
셋째, MESI 같은 캐시 일관성 프로토콜입니다.
이 세 가지가 멀티코어 환경에서 올바른 동기화를 보장합니다.
24. volatile 키워드는 어떤 의미가 있나요?
- volatile은 컴파일러에게 ‘이 변수는 예상치 못하게 바뀔 수 있으니 절대 캐싱하지 말고 매번 메모리에서 직접 읽어라’ 라고 지시하는 키워드입니다.
가시성은 보장하지만 원자성은 보장하지 않습니다.
25. 싱글코어가 아니라 멀티코어라면, 어떻게 동기화가 이뤄질까요?
- 멀티코어에서는 먼저 MESI 같은 캐시 일관성 프로토콜이 변수의 최신 값을 각 코어에 맞춰 주고,
그 위에서 CAS 같은 Atomic 연산과 Memory Barrier가 재배치 문제를 해결하며,
OS나 언어는 이 기반 위에서 락·스핀락 같은 동기화 프리미티브를 제공합니다.

26. 페이지 교체 알고리즘에 대해 설명해 주세요.
- 페이지 교체 알고리즘은 메모리 프레임이 가득 찬 상황에서 페이지 폴트가 발생했을 때 어떤 페이지를 내보내고 새로운 페이지를 적재할지 결정하는 알고리즘입니다.
성능 목표는 페이지 폴트를 최소화하는 것이며, FIFO, LRU, OPT, LFU, Clock 같은 알고리즘이 사용됩니다.
27. LRU 알고리즘은 어떤 특성을 이용한 알고리즘이라고 할 수 있을까요?
- LRU는 프로그램의 시간 지역성(Temporal Locality) 특성을 이용합니다.
즉 “최근에 사용된 페이지는 앞으로도 다시 사용할 가능성이 높다”고 가정하여, 가장 오래 사용되지 않은 페이지를 교체합니다.
28. LRU 알고리즘을 구현한다면, 어떻게 구현할 수 있을까요?
- LRU는 대개 HashMap + Doubly Linked List로 구현합니다.
HashMap은 페이지를 O(1)에 찾기 위해 사용하고, Linked List는 접근한 페이지를 리스트의 가장 앞으로 이동시키는 방식으로 “최근 사용 순서”를 유지합니다.
이 구조를 통해 삽입, 삭제, 갱신을 모두 O(1)에 처리할 수 있습니다.
29. LRU 알고리즘의 단점을 설명해 주세요. 이를 해결할 수 있는 대안에 대해서도 설명해 주세요.
- LRU는 구현 비용이 크고, 순차 접근 패턴에서 Thrashing이 발생하는 단점이 있습니다.
이를 해결하기 위해 실제 운영체제는 Clock 알고리즘을 사용해 구현 비용을 줄이고, 혹은 ARC, 2Q 같은 알고리즘을 사용해 LRU의 단점을 보완합니다.
30. File Descriptor와, File System에 에 대해 설명해 주세요.
- 파일 시스템은 저장장치를 파일과 디렉토리 구조로 추상화해 관리하는 구조이며, 파일의 메타데이터와 데이터 블록을 관리합니다.
파일 디스크립터는 유닉스 계열 시스템에서 파일을 참조하기 위한 정수 번호로, 프로세스는 이 번호를 통해 파일 읽기/쓰기 같은 작업을 수행합니다.
31. I-Node가 무엇인가요?
- I-node는 파일 시스템에서 파일의 메타데이터와 데이터 블록 위치 정보를 저장하는 구조체입니다.
파일명은 저장하지 않고, 디렉토리가 “파일명 → I-node 번호”를 매핑하는 방식으로 동작합니다.
32. 프로그래밍 언어 상에서 제공하는 파일 관련 함수 (Python - open(), Java - BufferedReader/Writer 등)은, 파일을 어떤 방식으로 읽어들이나요?
- Python이나 Java 모두 파일을 직접 디스크에서 읽는 것이 아니라,
open() → FD 발급 → read() 시스템 콜 → 커널이 페이지 캐시에서 데이터 제공
이런 구조로 동작합니다.

둘 다 사용자 공간에서 버퍼를 두어 작은 읽기 요청을 큰 단위로 묶어 처리하는 버퍼링된 I/O 방식을 사용해서 성능을 최적화합니다.
33. 동기와 비동기, 블로킹과 논블로킹의 차이에 대해 설명해 주세요.
- 동기/비동기는 작업 완료에 대한 관여 방식의 차이이고,
블로킹/논블로킹은 호출이 즉시 반환되는지 여부입니다.
동기는 호출자가 완료를 직접 확인해야 하고, 비동기는 완료를 다른 주체가 알려줍니다.
블로킹은 함수가 작업이 끝날 때까지 반환하지 않고, 논블로킹은 즉시 반환합니다.
34. 그렇다면, 동기이면서 논블로킹이고, 비동기이면서 블로킹인 경우는 의미가 있다고 할 수 있나요?
- 동기 논블로킹은 polling 기반으로 의미 있는 조합이고 실제로 사용됩니다.
반면 비동기 블로킹은 개념적으로 가능하지만 비동기의 장점을 상쇄해 실질적으로 거의 사용되지 않습니다.
35. I/O 멀티플렉싱에 대해 설명해 주세요.
- I/O 멀티플렉싱은 한 스레드가 여러 소켓을 동시에 감시하고, 준비된 소켓만 처리하는 기법입니다. select, poll, epoll 등이 대표적이며, 스레드를 많이 만들지 않고도 대규모 연결을 효율적으로 처리할 수 있습니다.
36. 논블로킹 I/O를 수행한다고 하면, 그 결과를 어떻게 수신할 수 있나요?
- 논블로킹 I/O는 즉시 반환하기 때문에 결과는 직접 반복 체크(polling)하거나, epoll 같은 I/O 멀티플렉싱으로 이벤트가 준비되었을 때 처리하거나, AIO처럼 콜백/이벤트 방식으로 수신할 수 있습니다.
